# .github/workflows/backup-verify.yml
name: Monthly Backup Restore Verification

on:
  schedule:
    - cron: "0 2 1 * *" # 1st of every month at 2 AM UTC
  workflow_dispatch:

jobs:
  verify:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    services:
      postgres:
        image: postgres:18
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U testuser"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
      - name: Install PostgreSQL 18 client (pg_restore/psql)
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y wget gnupg lsb-release ca-certificates

          # Add official PostgreSQL apt repo (pgdg) for Ubuntu noble
          wget -qO - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" \
            | sudo tee /etc/apt/sources.list.d/pgdg.list

          sudo apt-get update
          sudo apt-get install -y postgresql-client-18

          echo "pg_restore version:"
          /usr/lib/postgresql/18/bin/pg_restore --version
          echo "psql version:"
          /usr/lib/postgresql/18/bin/psql --version

      - name: Ensure AWS CLI is available
        run: |
          set -euo pipefail
          if command -v aws >/dev/null 2>&1; then
            echo "AWS CLI already installed:"
            aws --version
            exit 0
          fi

          echo "AWS CLI not found. Installing..."
          curl -sS "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip -q awscliv2.zip
          sudo ./aws/install
          aws --version

      - name: Download latest backup from R2
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
        run: |
          set -euo pipefail
          ENDPOINT="https://${R2_ACCOUNT_ID}.r2.cloudflarestorage.com"

          LATEST=$(
            aws s3 ls "s3://${R2_BUCKET}/" --endpoint-url "$ENDPOINT" \
              | awk '{print $4}' \
              | sort \
              | tail -n 1
          )

          if [ -z "${LATEST}" ]; then
            echo "No backups found in bucket: ${R2_BUCKET}"
            exit 1
          fi

          echo "Latest backup: ${LATEST}"
          aws s3 cp "s3://${R2_BUCKET}/${LATEST}" ./latest.dump --endpoint-url "$ENDPOINT"
          ls -lh ./latest.dump

      - name: Restore dump into temporary database (portable restore)
        run: |
          set -euo pipefail
          export PGPASSWORD="testpass"

          # Key flags for cross-environment restore:
          # --no-owner: ignore original DB role ownership
          # --no-acl:   ignore GRANT/REVOKE privileges
          /usr/lib/postgresql/18/bin/pg_restore \
            --no-owner \
            --no-acl \
            -h localhost \
            -U testuser \
            -d testdb \
            ./latest.dump

      - name: Verify restore (basic validation)
        run: |
          set -euo pipefail
          export PGPASSWORD="testpass"

          # Tables list (schema restored)
          /usr/lib/postgresql/18/bin/psql -h localhost -U testuser -d testdb -c "\dt"

          # A stronger signal: count how many tables exist
          COUNT=$(/usr/lib/postgresql/18/bin/psql -h localhost -U testuser -d testdb -tAc \
            "select count(*) from pg_catalog.pg_tables where schemaname='public';")
          echo "Public tables count: ${COUNT}"

          if [ "${COUNT}" -lt 5 ]; then
            echo "Restore completed but table count is unexpectedly low."
            exit 1
          fi

          echo "âœ… Backup restore verification successful."
